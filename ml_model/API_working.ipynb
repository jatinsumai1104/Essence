{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From E:\\App-Configs\\Anaconda\\envs\\hello-tf\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\App-Configs\\Anaconda\\envs\\hello-tf\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\App-Configs\\Anaconda\\envs\\hello-tf\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\App-Configs\\Anaconda\\envs\\hello-tf\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\App-Configs\\Anaconda\\envs\\hello-tf\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\App-Configs\\Anaconda\\envs\\hello-tf\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Python program to create\n",
    "# Image Classifier using CNN\n",
    "\n",
    "# Importing the required libraries\n",
    "import tensorflow as tf\n",
    "from tflearn import regression\n",
    "from tflearn import input_data, dropout, fully_connected\n",
    "from tflearn import conv_2d, max_pool_2d\n",
    "from flask import Flask\n",
    "import tflearn\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "'''Setting up the env'''\n",
    "\n",
    "TRAIN_DIR = 'train/'\n",
    "TEST_DIR = 'test/'\n",
    "UPLOADS_DIR = 'uploads/'\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "\n",
    "'''Setting up the model which will help with tensorflow models'''\n",
    "# MODEL_NAME = 'downvswithout-{}-{}.model'.format(LR, '6conv-basic')\n",
    "classes = ['22q11', 'Down', 'Angelman', 'Apert', 'CDL', 'FragileX', 'Marfan', 'Progeria', 'Sotos', 'TreacherCollins', 'Turner', 'Williams', 'Without']\n",
    "labels = [0]*len(classes)\n",
    "model = None\n",
    "\n",
    "def label_img(cond): \n",
    "    ele = classes.index(cond)\n",
    "    ret = labels.copy();\n",
    "    ret[ele] = 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for cond in classes:\n",
    "        for img in tqdm(os.listdir(TRAIN_DIR+'/'+cond)):\n",
    "            # labeling the images\n",
    "            label = label_img(cond)\n",
    "\n",
    "            path = os.path.join(TRAIN_DIR+'/'+cond, img)\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            try:\n",
    "#                 img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "#                 faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "#                 faces = faceCascade.detectMultiScale(img)\n",
    "#                 for (x, y, w, h) in faces:\n",
    "#                     img = img[y:y+h, x:x+w]\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            except Exception as ex:\n",
    "                continue\n",
    "            \n",
    "            # final step-forming the training data list with numpy array of the images\n",
    "            training_data.append([np.array(img), np.array(label), cond])\n",
    "\n",
    "    shuffle(training_data)\n",
    "\n",
    "    # saving our trained data for further uses if required\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    classes = ['Without']\n",
    "    for cond in classes:\n",
    "        for img in tqdm(os.listdir(TEST_DIR+'/'+cond)):\n",
    "            path = os.path.join(TEST_DIR+'/'+cond, img)\n",
    "            label = cond\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            try:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            except:\n",
    "                continue\n",
    "            testing_data.append([np.array(img), label, cond])\n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model():\n",
    "    global model\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "    convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "    convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "    convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "    convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "    convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "    convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "    convnet = dropout(convnet, 0.8)\n",
    "\n",
    "    convnet = fully_connected(convnet, 13, activation='softmax')\n",
    "    convnet = regression(convnet, optimizer='adam', learning_rate=LR,\n",
    "      loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "    model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "    \n",
    "    if os.path.exists(\"./model/model.tfl.index\"):\n",
    "        print(\"Model exists\")\n",
    "        model.load(\"model/model.tfl\")\n",
    "    else:\n",
    "        train_data = create_train_data()\n",
    "        length = len(train_data)//2\n",
    "    \n",
    "        train = train_data[:-length]\n",
    "        test = train_data[-length:]\n",
    "\n",
    "        '''Setting up the features and lables'''\n",
    "        # X-Features & Y-Labels\n",
    "\n",
    "        X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "        Y = [i[1] for i in train]\n",
    "        test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "        test_y = [i[1] for i in test]\n",
    "\n",
    "        '''Fitting the data into our model'''\n",
    "        model.fit({'input': X}, {'targets': Y}, n_epoch = 2, \n",
    "        validation_set =({'input': test_x}, {'targets': test_y}), \n",
    "        snapshot_step = 500, show_metric = True, run_id=\"disease_detection\") \n",
    "        model.save(\"model/model.tfl\")   \n",
    "        \n",
    "#     Splitting the testing data and training data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_model(path):\n",
    "    output = []\n",
    "    global model\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            img,\n",
    "            scaleFactor=1.3,\n",
    "            minNeighbors=3,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        for (x, y, w, h) in faces:\n",
    "            img = img[y:y+h, x:x+w]\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        data = img.reshape(IMG_SIZE, IMG_SIZE, 1) \n",
    "        model_out = model.predict([data])[0]\n",
    "        return [\"output\", model_out, classes[np.argmax(model_out)]]\n",
    "    except Exception as ex:\n",
    "        return str(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_model('uploads/jatin.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
